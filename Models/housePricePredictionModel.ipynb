{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 : Data Preparation\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"D:\\IMPORTANT\\Programming\\AIML\\Data\\melbourne_data.csv\")\n",
    "# print(data.iloc[:5, :3])\n",
    "# print(data.columns)\n",
    "# print(len(data))\n",
    "\n",
    "y = data.Price\n",
    "# print(y.iloc[:10])\n",
    "iFeatures = [\n",
    "        'Suburb', 'Address', 'Rooms',\n",
    "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom',\n",
    "       'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude',\n",
    "       'Longtitude', 'Regionname', 'Propertycount']\n",
    "\n",
    "X = data[iFeatures]\n",
    "# print(X.iloc[0:4, :])\n",
    "nan_count_per_column = X.isna().sum()\n",
    "# print(nan_count_per_column)\n",
    "\n",
    "# break into 3 sets. Train, Validation and Test data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, train_size=0.6)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, random_state = 1, train_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 : Transformers -> Imputer (for missing values) & OneHotEncoding (for cat data)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# OneHotEncoding\n",
    "categorical_features = ['Suburb', 'Address', 'Regionname', 'Date']\n",
    "\n",
    "# Declare a preprocessor transformer object to transform your categorical data columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cat', OneHotEncoder(handle_unknown = 'ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "# fit the transformer\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# transform your data sets\n",
    "X_train = preprocessor.transform(X_train)\n",
    "X_val = preprocessor.transform(X_val)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "# Declare imputer transformer to impute the data\n",
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "\n",
    "# fit the transformer\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# transform your data sets\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "X_val = imputer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 : Validation. (get best max_leaf_nodes count)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def get_mae(leaves : int):\n",
    "    print(f\"Training RF Model with {leaves} max_leaf_nodes\")\n",
    "\n",
    "    rfModel = RandomForestRegressor(random_state = 1, max_leaf_nodes = leaves, n_jobs=-1)\n",
    "    rfModel.fit(X_train, y_train)\n",
    "    return mean_absolute_error(y_val, rfModel.predict(X_val))\n",
    "\n",
    "mae_minima = float('inf')\n",
    "best_leaf_count = 0\n",
    "\n",
    "for leaves in range(100, 1000, 250):\n",
    "    mae = get_mae(leaves)\n",
    "    if (mae < mae_minima):\n",
    "        mae_minima = mae\n",
    "        best_leaf_count = leaves\n",
    "\n",
    "print(f\"Best leaf count : {best_leaf_count}\") # its 850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the Model...\n"
     ]
    }
   ],
   "source": [
    "# STEP 4 : Testing\n",
    "\n",
    "print(\"Testing the Model...\")\n",
    "\n",
    "# Declare the model\n",
    "final_model = RandomForestRegressor(random_state = 1, n_jobs = -1, max_leaf_nodes=best_leaf_count)\n",
    "\n",
    "# Fit the model\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the model\n",
    "predictions = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results:\n",
      "MAE (Mean Absolute Error) : $ 169002.05877761415\n",
      "MSE (Mean Squared Error) : 79546025934.80173\n",
      "MAPE (Mean Absolute Percentage Error) : 15.54%\n"
     ]
    }
   ],
   "source": [
    "# STEP 5 : Results\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "print(\"Here are the results:\")\n",
    "print(f\"MAE (Mean Absolute Error) : $ {mae}\")\n",
    "print(f\"MSE (Mean Squared Error) : {mse}\")\n",
    "print(f\"MAPE (Mean Absolute Percentage Error) : {(mape*100) :.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MAE of $173,588.85:\n",
    "This means your model's average prediction error is approximately $173,588.85. Depending on the range of house prices in your dataset, this could be a significant or minor error. For high-value houses, this might be more acceptable than for lower-value houses.\n",
    "\n",
    "2. MSE of $80,870,750,974.31:\n",
    "This large value indicates that there are some significant prediction errors. The squaring of errors in MSE means that larger errors are disproportionately impacting this metric. High MSE suggests that your model may be struggling with outliers or large variations in predictions.\n",
    "\n",
    "3. MAPE of 16.26%:\n",
    "A MAPE of 16.26% means that, on average, your predictions are off by about 16.26% from the actual values. For house price predictions, this could be considered moderately high. Typically, a MAPE below 10% is desirable, especially in real estate where accurate pricing is critical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
